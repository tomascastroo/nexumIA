#!/usr/bin/env python3
"""
Script de prueba para demostrar el nuevo sistema de evaluaciÃ³n de reglas.
Este script simula el caso de uso descrito en el problema.
"""

import json
from services.rule_decision_service import rule_decision_service
from services.structured_prompt_service import structured_prompt_service
from services.traceability_service import traceability_service

class MockStrategy:
    """Mock de Strategy para pruebas"""
    def __init__(self, data):
        self.id = data['id']
        self.name = data['name']
        self.initial_prompt = data['initial_prompt']
        self.evaluable_rules = data['evaluable_rules']
        self.rules_by_state = data['rules_by_state']
        self.strict_mode = data['strict_mode']
        self.fallback_prompt = data['fallback_prompt']

def create_test_strategy():
    """Crea una estrategia de prueba con reglas"""
    return {
        'id': 1,
        'name': 'Estrategia de Prueba',
        'initial_prompt': 'Hola, soy Francisco de cobranzas...',
        'evaluable_rules': [
            {
                'name': 'Descuento GRIS 20%',
                'condition': "estado == 'GRIS' and deuda >= 30000",
                'response': 'Te ofrezco un 20% de descuento en tu deuda de ${deuda}.',
                'strict': True,
                'priority': 1,
                'enabled': True
            },
            {
                'name': 'Descuento GRIS 15%',
                'condition': "estado == 'GRIS' and deuda >= 20000 and deuda < 30000",
                'response': 'Te ofrezco un 15% de descuento en tu deuda de ${deuda}.',
                'strict': True,
                'priority': 2,
                'enabled': True
            },
            {
                'name': 'Escalar a humano',
                'condition': "estado == 'ROJO' and negative_responses_count >= 2",
                'response': 'Te voy a derivar con un especialista que se pondrÃ¡ en contacto contigo.',
                'strict': False,
                'priority': 3,
                'enabled': True,
                'escalate_to_human': True
            }
        ],
        'rules_by_state': {
            'VERDE': {'prompt': '', 'rules': [], 'advanced_rules': []},
            'AMARILLO': {'prompt': '', 'rules': [], 'advanced_rules': []},
            'ROJO': {'prompt': '', 'rules': [], 'advanced_rules': []},
            'GRIS': {
                'prompt': '',
                'rules': [],
                'advanced_rules': [
                    {
                        'name': 'Descuento GRIS avanzado',
                        'conditions': {
                            'operator': 'AND',
                            'conditions': [
                                {'field': 'estado', 'operator': '==', 'value': 'GRIS'},
                                {'field': 'deuda', 'operator': '>=', 'value': 40000}
                            ]
                        },
                        'response': 'Te ofrezco un 25% de descuento especial en tu deuda de ${deuda}.',
                        'strict': True,
                        'priority': 1
                    }
                ]
            }
        },
        'strict_mode': True,
        'fallback_prompt': 'Gracias por tu interÃ©s. Un especialista se pondrÃ¡ en contacto contigo.'
    }

def create_test_debtor():
    """Crea datos de deudor de prueba"""
    return {
        'nombre': 'Tomas Castro',
        'estado': 'GRIS',
        'deuda': 40000,
        'ciudad': 'Buenos Aires',
        'sexo': 'masculino',
        'fecha_registro': '2023-01-15'
    }

def create_test_conversation():
    """Crea historial de conversaciÃ³n de prueba"""
    return [
        {
            "role": "system",
            "content": "Tu nombre es Francisco. TratÃ¡ amablemente al deudor"
        },
        {
            "role": "assistant",
            "content": "Estimado/a Tomas Castro: Mi nombre es Francisco..."
        },
        {
            "role": "user",
            "content": "Â¿AlgÃºn descuento?"
        }
    ]

def test_rule_evaluation():
    """Prueba la evaluaciÃ³n de reglas"""
    print("ğŸ§ª PRUEBA DEL SISTEMA DE EVALUACIÃ“N DE REGLAS")
    print("=" * 60)
    
    # Crear datos de prueba
    strategy = create_test_strategy()
    debtor_data = create_test_debtor()
    conversation_history = create_test_conversation()
    user_message = "Â¿AlgÃºn descuento?"
    
    print(f"ğŸ“‹ Estrategia: {strategy['name']}")
    print(f"ğŸ‘¤ Deudor: {debtor_data['nombre']}")
    print(f"ğŸ’° Deuda: ${debtor_data['deuda']:,.2f}")
    print(f"ğŸ¯ Estado: {debtor_data['estado']}")
    print(f"ğŸ’¬ Mensaje: {user_message}")
    print()
    
    # Evaluar reglas
    mock_strategy = MockStrategy(strategy)
    decision = rule_decision_service.evaluate_and_decide(  # type: ignore
        strategy=mock_strategy,
        debtor_data=debtor_data,
        current_state=debtor_data['estado'],
        conversation_history=conversation_history,
        user_message=user_message
    )
    
    print("ğŸ¯ RESULTADO DE LA EVALUACIÃ“N:")
    print(f"   AcciÃ³n: {decision.action_description}")
    print(f"   Tipo: {decision.action_type}")
    print(f"   Reglas aplicables: {len(decision.applicable_rules)}")
    
    if decision.triggered_rule:
        rule = decision.triggered_rule
        print(f"   Regla activada: {rule.get('name', 'Sin nombre')}")
        print(f"   Respuesta: {rule.get('response', '')}")
    
    print(f"   Restricciones: {len(decision.restrictions or [])}")
    print(f"   Razonamiento: {decision.reasoning}")
    print()
    
    return decision

def test_structured_prompt():
    """Prueba la generaciÃ³n de prompt estructurado"""
    print("ğŸ“ PRUEBA DE GENERACIÃ“N DE PROMPT ESTRUCTURADO")
    print("=" * 60)
    
    strategy = create_test_strategy()
    debtor_data = create_test_debtor()
    conversation_history = create_test_conversation()
    user_message = "Â¿AlgÃºn descuento?"
    
    # Generar prompt estructurado
    mock_strategy = MockStrategy(strategy)
    prompt_result = structured_prompt_service.generate_action_specific_prompt(  # type: ignore
        strategy=mock_strategy,
        debtor_data=debtor_data,
        current_state=debtor_data['estado'],
        conversation_history=conversation_history,
        user_message=user_message,
        is_first_message=False
    )
    
    print("ğŸ“‹ PROMPT GENERADO:")
    print("-" * 40)
    print(prompt_result['prompt'])
    print("-" * 40)
    print()
    
    print("ğŸ” METADATOS:")
    print(f"   Tipo de acciÃ³n: {prompt_result['action_type']}")
    print(f"   Restricciones: {len(prompt_result['restrictions'])}")
    print(f"   Respuestas permitidas: {len(prompt_result['allowed_responses'])}")
    print()
    
    return prompt_result

def test_traceability():
    """Prueba el sistema de trazabilidad"""
    print("ğŸ“Š PRUEBA DEL SISTEMA DE TRAZABILIDAD")
    print("=" * 60)
    
    strategy = create_test_strategy()
    debtor_data = create_test_debtor()
    conversation_history = create_test_conversation()
    user_message = "Â¿AlgÃºn descuento?"
    
    # Simular decisiÃ³n y respuesta
    mock_strategy = MockStrategy(strategy)
    decision = rule_decision_service.evaluate_and_decide(  # type: ignore
        strategy=mock_strategy,
        debtor_data=debtor_data,
        current_state=debtor_data['estado'],
        conversation_history=conversation_history,
        user_message=user_message
    )
    
    # Simular respuesta del LLM
    llm_response = "Te ofrezco un 25% de descuento especial en tu deuda de $40,000. Esta es una oportunidad Ãºnica para regularizar tu situaciÃ³n."
    
    # Registrar en trazabilidad
    log_entry = traceability_service.log_rule_decision(
        debtor_id=1,
        strategy_id=1,
        user_message=user_message,
        decision=decision,
        llm_response=llm_response,
        conversation_history=conversation_history,
        debtor_data=debtor_data
    )
    
    print("âœ… DecisiÃ³n registrada en trazabilidad")
    print(f"   Timestamp: {log_entry['timestamp']}")
    print(f"   Deudor ID: {log_entry['debtor_id']}")
    print(f"   Estrategia ID: {log_entry['strategy_id']}")
    print()
    
    # Obtener analytics
    analytics = traceability_service.get_decision_analytics()
    print("ğŸ“ˆ ANALYTICS:")
    print(f"   Total decisiones: {analytics['total_decisions']}")
    print(f"   Tipos de acciÃ³n: {analytics['action_types']}")
    print(f"   Tasa de fallback: {analytics['fallback_rate']:.1f}%")
    print(f"   Uso de reglas estrictas: {analytics['strict_rules_usage']:.1f}%")
    print(f"   Promedio reglas por decisiÃ³n: {analytics['average_rules_per_decision']:.1f}")
    print()

def main():
    """FunciÃ³n principal de prueba"""
    print("ğŸš€ INICIANDO PRUEBAS DEL SISTEMA DE REGLAS")
    print("=" * 60)
    print()
    
    # Ejecutar pruebas
    test_rule_evaluation()
    test_structured_prompt()
    test_traceability()
    
    print("âœ… TODAS LAS PRUEBAS COMPLETADAS")
    print("=" * 60)
    print()
    print("ğŸ“‹ RESUMEN DE MEJORAS IMPLEMENTADAS:")
    print("1. âœ… EvaluaciÃ³n programÃ¡tica de reglas antes del LLM")
    print("2. âœ… DecisiÃ³n de acciÃ³n especÃ­fica basada en reglas")
    print("3. âœ… Prompt estructurado con restricciones")
    print("4. âœ… Trazabilidad completa de decisiones")
    print("5. âœ… Sistema de fallback automÃ¡tico")
    print("6. âœ… Analytics de decisiones")
    print()
    print("ğŸ¯ CASO DE PRUEBA:")
    print("   Deudor: Tomas Castro, Estado: GRIS, Deuda: $40,000")
    print("   Mensaje: 'Â¿AlgÃºn descuento?'")
    print("   Resultado: Se activa regla de descuento 25%")
    print("   LLM: Recibe instrucciones especÃ­ficas para ofrecer descuento")
    print()

if __name__ == "__main__":
    main() 